{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic_Procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The reassign procedure is not implemented. This part of the code is not completed and can be omitted. In case of using it, it must be reviewed first. There are aspects that need to be check, for example the value of vnf_type (equal to f_type or next_vnf type??)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(dir_data, file_name):\n",
    "    \"\"\"THis function imports the data that it is in dir_data+file_name\"\"\"\n",
    "    with open (dir_data+file_name, \"rb\") as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(file_name, file_data):\n",
    "    \"\"\"Esta funcion me permite salvar en un fichero con nombbre file_data la información contenida en file_data\"\"\"\n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        pickle.dump(file_data, fp)\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to initial solution\n",
    "dir_data = 'path_initial_solution'  \n",
    "\n",
    "\n",
    "# Number of users (i.e., PDU sessions or SFCR)\n",
    "S = import_data(dir_data, \"S\") \n",
    "\n",
    "# Session information\n",
    "N_sfc_type = import_data(dir_data, \"N_sfc_type_S\"+str(S)) \n",
    "Dict_Tsfc_s = import_data(dir_data, \"Dict_Tsfc_s_S\"+str(S)) \n",
    "Dict_C_s = import_data(dir_data, \"Dict_C_s_S\"+str(S)) \n",
    "Dict_Lreq_s = import_data(dir_data, \"Dict_Lreq_s_S\"+str(S)) \n",
    "Dict_beta_s = import_data(dir_data, \"Dict_beta_s_S\"+str(S)) \n",
    "Source_BS = import_data(dir_data, \"Source_BS_S\"+str(S)) \n",
    "\n",
    "\n",
    "# Nodes\n",
    "# Candidate locations\n",
    "Nc = import_data(dir_data, \"ListMECInstalled\")        # candidate coordenadas\n",
    "Nc = sorted(Nc , key=lambda k: [k[1], k[0]])\n",
    "capacity_nc = import_data(dir_data, \"Dict_C_c\") \n",
    "Available_nc = list(capacity_nc.keys())               # inicialmente todos los candidatos tienen capacidad\n",
    "# access nodes\n",
    "Nr = import_data(dir_data, \"BS_pos\")\n",
    "Nr = sorted(Nr , key=lambda k: [k[1], k[0]])\n",
    "# Set of all nodes. \n",
    "N = Nc + Nr \n",
    "\n",
    "\n",
    "# paths data \n",
    "Edges = import_data(dir_data,\"Edges\")                               # dict with key nodes_id (en & ran) and value latency\n",
    "Dict_Links_Capacity = import_data(dir_data,\"Dict_Links_Capacity\")   # dict with key nodes_id (en & ran) and value bandwidth\n",
    "Paths = import_data(dir_data,\"Paths\")                     \n",
    "Paths_links_mapping = import_data(dir_data,'Paths_links_mapping')   # H^p_uv: 1 if path p ∈ P is mapped to physical link (u,v) ∈ E\n",
    "\n",
    "\n",
    "# VNFs Data\n",
    "Dict_C_t = import_data(dir_data,'Dict_C_t')             # Processing capacity of VNF of type t ∈ T         \n",
    "Dict_D_proc = import_data(dir_data,'Dict_D_proc')       # d_t: Processing delay of VNF of type t ∈ T\n",
    "M_t_imported = import_data(dir_data,'M_t')              # M_t: Maximum number of instances of type t ∈ T. Compute upon service demands and VNF capacity\n",
    "T = import_data(dir_data,'T')                           # T: Types of VNFs\n",
    "T_extended = T+1                                        # Extending T dataset to include RANs as an special VNF type\n",
    "T_dn = import_data(dir_data,'T_dn')                     # Processing time of data network nodes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightFactors List\n",
    "WeightFactors = [0.4, 0.4, 0.2]\n",
    "\n",
    "# Normalization parameters\n",
    "max_latency = 100  #PDT DEFINIR\n",
    "max_upf = round(sum(capacity_nc.values())/min(capacity_ct.values()))\n",
    "max_server = len(capacity_nc)\n",
    "NormalizationValues = [max_server, max_upf, max_latency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_aupf = 0\n",
    "Cap_iupf = 0\n",
    "Cap_miupf = 0\n",
    "t1, t2, t3 = 0,0,0\n",
    "\n",
    "for user in range(S):\n",
    "    Cap_aupf +=  Dict_C_s[user+1]\n",
    "    if Dict_Tsfc_s[user+1]==3:\n",
    "        Cap_aupf +=  Dict_C_s[user+1]\n",
    "        Cap_miupf +=  Dict_C_s[user+1]\n",
    "        t3 +=1\n",
    "    elif Dict_Tsfc_s[user+1]==2:  \n",
    "        Cap_iupf +=  Dict_C_s[user+1]\n",
    "        t2 +=1\n",
    "    else:  \n",
    "        t1 +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the set of links between candidate nodes and ran-candidates\n",
    "\n",
    "Edge_candidates = {}\n",
    "Edge_rans_candidates = {}\n",
    "\n",
    "for k,v in Edges.items():\n",
    "    if k[0] <= len(Nc) and k[1] <= len(Nc):\n",
    "        Edge_candidates[k] = v\n",
    "    else:\n",
    "        Edge_rans_candidates[k] = v\n",
    "\n",
    "if len(Edge_candidates) + len(Edge_rans_candidates) != len(Edges):\n",
    "    print('Error: There was something wrong in the splitting process')\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the general parameters for each type SFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Parameters for each type of SFCR\n",
    "\n",
    "if N_sfc_type==3:                              # T: Number of VNFs types 1:PSA,  2:IUPF,3: M-IUPF, 4:RAN\n",
    "    Ran_type = 4\n",
    "    B_sfc_type = [1,1,2]                       # No. of branches in each type of SFC\n",
    "    F_sfc_type = [[1,2],[1,2,3],[1, 2, 3, 4]]  # VNFs in each type of SFC\n",
    "    T_sfc_type = [[1,4],[2,1,4],[3,1,1,4]]     # Type for each VNF in SFC \n",
    "    K_sfc_type = [[1,1],[1,1,1],[1,0,0,1]]     # Indicates if a VNF instance is common to all the branches or not\n",
    "    P_fbs_sfc_type = [[[1,1]], \n",
    "                      [[1,1,1]], \n",
    "                      [[1,1,0,1],[1,0,1,1]]]   # Indicates if a VNF is present or not in a branch: Index[type,branch,vnf]\n",
    "    O_sbfg_sfc_type  = [[[[0,0], [1,0]]],\n",
    "                        [[[0,1,0],[0,0,0],[1,0,0]]],\n",
    "                        [[[0,1,0,0],[0,0,0,0],[0,0,0,0],[1,0,0,0]],\n",
    "                        [[0,0,1,0],[0,0,0,0],[0,0,0,0],[1,0,0,0]]]]  #Indicates if a VNF f goes before g in a branch\n",
    "\n",
    "if N_sfc_type==2:                               # T: Number of VNFs types 1:PSA,  2:IUPF, 3:RAN\n",
    "    Ran_type = 3\n",
    "    B_sfc_type = [1,1]                          # No. of branches in each type of SFC\n",
    "    F_sfc_type = [[1,2],[1,2,3]]                # VNFs in each type of SFC\n",
    "    T_sfc_type = [[1,3],[2,1,3]]                # Type for each VNF in SFC \n",
    "    K_sfc_type = [[1,1],[1,1,1]]                # Indicates if a VNF instance is common to all the branches or not\n",
    "    P_fbs_sfc_type = [[[1,1]], \n",
    "                      [[1,1,1]]]                # Indicates if a VNF is present or not in a branch: Index[type,branch,vnf]\n",
    "    O_sbfg_sfc_type  = [[[[0,0], [1,0]]],\n",
    "                        [[[0,1,0],[0,0,0],[1,0,0]]]]  #Indicates if a VNF f goes before g in a branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining PDU sessions  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the data of each session PDU (demand, A-UPF number, BS source)\n",
    "List_F_s = []\n",
    "List_T_s = []\n",
    "List_K_s = []\n",
    "List_P_s = []\n",
    "List_O_s = []\n",
    "List_B_s = []\n",
    "List_NumVNF_s = []\n",
    "List_R_s = []  # It has for each session the tuple (s,f,t,m,c)\n",
    "List_Lreq_s = []\n",
    "List_C_s = []\n",
    "List_beta_s = []\n",
    "List_L_prop_s = []\n",
    "\n",
    "for k,v in Dict_Tsfc_s.items():\n",
    "    List_F_s.append(F_sfc_type[v-1])\n",
    "    List_T_s.append(T_sfc_type[v-1])\n",
    "    List_K_s.append(K_sfc_type[v-1])\n",
    "    List_P_s.append(P_fbs_sfc_type[v-1])\n",
    "    List_B_s.append(B_sfc_type[v-1])\n",
    "    List_NumVNF_s.append(len(F_sfc_type[v-1]))\n",
    "    List_R_s.append(Nr.index(Source_BS[k])+1+len(Nc))\n",
    "    List_Lreq_s.append(Dict_Lreq_s[k])\n",
    "    aux_list = []\n",
    "    for b in P_fbs_sfc_type[v-1]:\n",
    "        L_proc = Dict_D_proc[Ran_type]+T_dn\n",
    "        for ind in range(len(b)):\n",
    "            if b[ind]==1:\n",
    "                L_proc += 2*Dict_D_proc[T_sfc_type[v-1][ind]]\n",
    "        aux_list.append((Dict_Lreq_s[k]-L_proc)/2) \n",
    "    List_L_prop_s.append(aux_list)\n",
    "    List_C_s.append(Dict_C_s[k])\n",
    "    List_beta_s.append(Dict_beta_s[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>Latency</th>\n",
       "      <th>L_prop</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Bw</th>\n",
       "      <th>SourceBS</th>\n",
       "      <th>Branches</th>\n",
       "      <th>VNFs</th>\n",
       "      <th>NumVNFs</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Type</th>\n",
       "      <th>Common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>[150.0]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>[50.0, 50.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1, 1, 0], [1, 0, 1]]</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>900</td>\n",
       "      <td>[50.0, 50.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1, 1, 0], [1, 0, 1]]</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>900</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>900</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>1000</td>\n",
       "      <td>[100.0, 100.0]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1, 1, 0], [1, 0, 1]]</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>1000</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SessionId  Latency          L_prop  Demand  Bw  SourceBS  Branches  \\\n",
       "0            1     1000         [150.0]     0.1  10        54         1   \n",
       "1            2      900    [50.0, 50.0]     0.2  20        45         2   \n",
       "2            3      900          [50.0]     0.2  10        92         1   \n",
       "3            4      900    [50.0, 50.0]     0.2  20        79         2   \n",
       "4            5      900          [50.0]     0.1  20       108         1   \n",
       "..         ...      ...             ...     ...  ..       ...       ...   \n",
       "195        196      900         [100.0]     0.2  10        47         1   \n",
       "196        197      900          [50.0]     0.2  20        44         1   \n",
       "197        198     1000  [100.0, 100.0]     0.1  10        93         2   \n",
       "198        199     1000         [100.0]     0.2  10        80         1   \n",
       "199        200     1000         [100.0]     0.2   1        54         1   \n",
       "\n",
       "          VNFs  NumVNFs                Presence       Type     Common  \n",
       "0          [1]        1                   [[1]]        [1]        [1]  \n",
       "1    [1, 2, 3]        3  [[1, 1, 0], [1, 0, 1]]  [3, 1, 1]  [1, 0, 0]  \n",
       "2       [1, 2]        2                [[1, 1]]     [2, 1]     [1, 1]  \n",
       "3    [1, 2, 3]        3  [[1, 1, 0], [1, 0, 1]]  [3, 1, 1]  [1, 0, 0]  \n",
       "4       [1, 2]        2                [[1, 1]]     [2, 1]     [1, 1]  \n",
       "..         ...      ...                     ...        ...        ...  \n",
       "195        [1]        1                   [[1]]        [1]        [1]  \n",
       "196     [1, 2]        2                [[1, 1]]     [2, 1]     [1, 1]  \n",
       "197  [1, 2, 3]        3  [[1, 1, 0], [1, 0, 1]]  [3, 1, 1]  [1, 0, 0]  \n",
       "198     [1, 2]        2                [[1, 1]]     [2, 1]     [1, 1]  \n",
       "199     [1, 2]        2                [[1, 1]]     [2, 1]     [1, 1]  \n",
       "\n",
       "[200 rows x 12 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SessionInfo = pd.DataFrame()\n",
    "SessionInfo['SessionId'] = list(Dict_Tsfc_s.keys())\n",
    "SessionInfo['Latency'] = List_Lreq_s\n",
    "SessionInfo['L_prop'] = List_L_prop_s\n",
    "SessionInfo['Demand'] = List_C_s\n",
    "SessionInfo['Bw'] = List_beta_s\n",
    "SessionInfo['SourceBS'] = List_R_s \n",
    "SessionInfo['Branches'] = List_B_s\n",
    "SessionInfo['VNFs'] = List_F_s \n",
    "SessionInfo['NumVNFs'] = List_NumVNF_s \n",
    "SessionInfo['Presence'] = List_P_s \n",
    "SessionInfo['Type'] = List_T_s \n",
    "SessionInfo['Common'] = List_K_s \n",
    "\n",
    "SessionInfo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_classifier(session_info, available_c):\n",
    "    \"\"\" \n",
    "    This function classified the sessions as critic or not depending on their number of available candidates\n",
    "    Input:\n",
    "    - session_info: DF with info about sessions\n",
    "    - available_c: List of available candidates for the VNf placement\n",
    "    \"\"\"\n",
    "    \n",
    "    List_critic_s = []     # 1 if critic, 0 otherwise\n",
    "    List_Numcand_s = []\n",
    "    List_candidates_s = []\n",
    "    \n",
    "    for index, row in session_info.iterrows():\n",
    "        aux_list = determine_candidates(row['SourceBS'], row['L_prop'], available_c)\n",
    "\n",
    "        List_Numcand_s.append(len(aux_list))\n",
    "        List_candidates_s.append(aux_list)\n",
    "        if len(row['Type'])==1:\n",
    "\n",
    "            if len(aux_list)<=1:\n",
    "                List_critic_s.append(1)\n",
    "            else:\n",
    "                List_critic_s.append(0)\n",
    "                \n",
    "        else:\n",
    "            if len(aux_list)<=2:\n",
    "                List_critic_s.append(1)\n",
    "            else:\n",
    "                List_critic_s.append(0)\n",
    "\n",
    "    session_info['Critic'] = List_critic_s \n",
    "    session_info['NumCand'] = List_Numcand_s \n",
    "    session_info['Candidates'] = List_candidates_s \n",
    "    \n",
    "    return session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_candidates(source_vnf, Lprop_vnf):\n",
    "    \"\"\"\n",
    "    This fucntion determines the candidates for the placement of a given vnf given the propagation delay budget.\n",
    "    Inputs:\n",
    "    -source_vnf: The id of the source node (the previous vnf in the branch of the current vnf)\n",
    "    -Lprop_vnf. the latency budget for the propagation delay    \n",
    "    Output:\n",
    "    - List_c: A list with the position of the candidates\n",
    "    \"\"\"      \n",
    "    List_c = []\n",
    "    \n",
    "    for kp, vp in Paths.items():   # kp, vp: path, propagation delay\n",
    "        if kp[0] == source_vnf and vp <= min(Lprop_vnf):\n",
    "            if kp[1] not in List_c:\n",
    "                List_c.append(kp[1]) \n",
    "                \n",
    "    return List_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_part1():\n",
    "    \"\"\"\n",
    "    This part reassigns an existent VNf of an already assigned SFCR\n",
    "    \"\"\"\n",
    "\n",
    "    Copy_ServersCap = copy.deepcopy(ServersCap)\n",
    "    Copy_LinksCap = copy.deepcopy(LinksCap)\n",
    "    Copy_OpenServers = copy.deepcopy(OpenServers)\n",
    "    Copy_VNFInstances = copy.deepcopy(VNFInstances)             # the key is the type of VNF and the value is a list of instances id\n",
    "    Copy_VNFCapacity = copy.deepcopy(VNFCapacity)               # dict of dict, main dict key=type, valueis a dict key=instance_id & value=available cap\n",
    "    Copy_NodeVNFInstances = copy.deepcopy(NodeVNFInstances)     # dict of dict, main dict key=node id, valueis a dict key=vnf_type & value=instance id\n",
    "    Copy_SFCMapping = copy.deepcopy(SFCMapping)                 # dict of dict, main dict key=pdu id, value= dict key=vnf_id(f)& value=type,instance_id,nodeId\n",
    "\n",
    "    for k1,v1 in Dict_Unfeasiblecandidate.items():\n",
    "\n",
    "        # Checking if failure is due to C17 constraint only\n",
    "        if len(v1)==1 and ('C17'in v1 or 'C16' in v1):\n",
    "            vnf_type = 1 #psa   \n",
    "\n",
    "            # verify if there is a PSA in k1 with available capacity\n",
    "            if len(NodeVNFInstances.get(k1, {}))!=0: \n",
    "\n",
    "                if len(NodeVNFInstances[k1].get(vnf_type, []))==0:  #no psa in k1, we should try to create one\n",
    "                    if Copy_ServersCap[k1]>= capacity_ct[vnf_type]:\n",
    "                        flag_create_psa = True\n",
    "                    else:\n",
    "                        flag_create_psa = False\n",
    "                        print(\"NO PSA INSTANCE OR CAPACITY TO CREATE ONE, NO CREO Q ESTO PASE\")\n",
    "                else:\n",
    "                    flag_create_psa = True\n",
    "                    #verify if there is a psa with available capacity\n",
    "                    for inst in NodeVNFInstances[k1][vnf_type]:\n",
    "                        if VNFCapacity[vnf_type][inst] >= row['Demand']:\n",
    "                            new_instance = inst\n",
    "                            flag_create_psa = False\n",
    "                            break\n",
    "                    if flag_create_psa and (Copy_ServersCap[k1]< capacity_ct[vnf_type]): \n",
    "                        flag_create_psa = False\n",
    "                        print(\"NO PSA INSTANCE con CAPACITY or capacity TO CREATE ONE, NO CREO Q ESTO PASE\")\n",
    "                        \n",
    "            else:  \n",
    "                # unopen server (no active server)\n",
    "                Copy_OpenServers.append(k1)                     #update set of open servers\n",
    "                flag_create_psa = True\n",
    "          \n",
    "            if flag_create_psa:\n",
    "                Copy_ServersCap[k1]-= capacity_ct[vnf_type]     #update server capacity\n",
    "                new_instance = len(Copy_VNFInstances.get(vnf_type, []))+1\n",
    "                Copy_VNFInstances.setdefault(vnf_type,[]).append(new_instance)\n",
    "                Copy_VNFCapacity[vnf_type] = VNFCapacity.setdefault(vnf_type,{})\n",
    "                Copy_VNFCapacity[vnf_type][new_instance] = capacity_ct[vnf_type]\n",
    "                Copy_NodeVNFInstances.setdefault(k1, {}).setdefault(vnf_type,[]).append(new_instance)\n",
    "                \n",
    "            # Searching for SFCR to reassign to this PSA instance\n",
    "            candidate_near_k1 = {}\n",
    "            for c in List_c:\n",
    "                if c!=k1:\n",
    "                    if (k1,c) in Edges.keys():\n",
    "                        candidate_near_k1[c]=Edges[(k1,c)] \n",
    "            sort_candidate_near_k1 = sorted(candidate_near_k1.items(), key=lambda x: x[1])\n",
    "\n",
    "            for nc in sort_candidate_near_k1:\n",
    "\n",
    "                #Verifyng if the candidate has at least one PSA\n",
    "                list_psa_nc = NodeVNFInstances.get(nc[0],{}).get(vnf_type, [])\n",
    "\n",
    "                for psa in list_psa_nc:\n",
    "                    for sfcr in VNFSFCAssigned[vnf_type][psa]:\n",
    "                        for index, row_sfcr in SortedSessionInfo.loc[SortedSessionInfo['SessionId'] == sfcr].iterrows():\n",
    "                            break\n",
    "                        if row_sfcr['Demand']>=row['Demand'] and VNFCapacity[vnf_type][new_instance]>=row_sfcr['Demand']:\n",
    "                            latency_sfcr = 0\n",
    "                            possible_paths = []\n",
    "                            for path in SFCMapping[sfcr]['Paths']:\n",
    "                                latency_sfcr += Paths[path]\n",
    "                                if path[1]==nc[0]:\n",
    "                                    possible_paths.append(path)\n",
    "\n",
    "                            if len(possible_paths)==1: # it's easy to find the source\n",
    "                                source_sfcr = possible_paths[0][0]\n",
    "                                #verifying  latency\n",
    "                                latency_budget = row_sfcr['L_prop'][0] - latency_sfcr+Paths[possible_paths[0]]\n",
    "                                flag_latency = False\n",
    "\n",
    "                                for k,v in Paths.items():\n",
    "                                    if k[0]==source_sfcr and k[1]==k1:\n",
    "                                        if v <= latency_budget:\n",
    "                                            flag_latency= True\n",
    "                                            break\n",
    "\n",
    "                                if flag_latency: # old instance in SFCMapping\n",
    "                                    for vnf_id, mapp in SFCMapping[sfcr]['VNFs'].items():\n",
    "                                        if mapp[2]==nc[0] and mapp[0]==vnf_type:\n",
    "                                            old_instance =  mapp[1]\n",
    "\n",
    "                                    # We should release links capacity before verfying the constraints\n",
    "                                    for link,v in Paths_links_mapping[possible_paths[0]].items():\n",
    "                                        if v==1: \n",
    "                                            #update link capacity\n",
    "                                            Copy_LinksCap[link] += row_sfcr['Bw']\n",
    "\n",
    "                                    List_const, Selected_path, VariableValues = verify_candidate(k1, source_sfcr, vnf_type, row_sfcr)\n",
    "\n",
    "                                    if len(List_const)== 0 and Selected_path != None:   #Feasible candidate\n",
    "                                        #updating sfcr data\n",
    "                                        Copy_VNFCapacity[vnf_type][new_instance]-= row_sfcr['Demand']  # new location\n",
    "                                        Copy_VNFCapacity[vnf_type][old_instance]+= row_sfcr['Demand']  # old location\n",
    "\n",
    "                                        for link,v in Paths_links_mapping[Selected_path].items():\n",
    "                                            if v==1:\n",
    "                                                 #update link capacity\n",
    "                                                Copy_LinksCap[link]-= row_sfcr['Bw']\n",
    "\n",
    "                                        Copy_SFCMapping[row_sfcr['SessionId']]['VNFs'][vnf_id] = (vnf_type, \n",
    "                                                                                                  new_instance, \n",
    "                                                                                                  k1)\n",
    "                                        Copy_SFCMapping[row_sfcr['SessionId']]['Paths'] = [Selected_path if x== possible_paths[0]\n",
    "                                                                                           else x for x in Copy_SFCMapping[row_sfcr['SessionId']]\n",
    "                                                                                           ['Paths']]\n",
    "\n",
    "                                        return (Copy_ServersCap,Copy_LinksCap,Copy_OpenServers,Copy_VNFInstances,\n",
    "                                                Copy_VNFCapacity,Copy_NodeVNFInstances, Copy_SFCMapping)\n",
    "\n",
    "    print(\"This is an unfeasible case pending of analisis\")\n",
    "    \n",
    "    return ServersCap, LinksCap, OpenServers, VNFInstances, VNFCapacity, NodeVNFInstances, SFCMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_candidate(solution_, c, source_vnf, vnf_type, row):\n",
    "    \"\"\"\n",
    "    this function verifies that none constarint is violated if vnf is placed at this location. \n",
    "    It also verifies the existence of a path with available capacity. In case of more than one path it returns \n",
    "    the shortest one\n",
    "    Inputs:\n",
    "    -c: candiate node(id)\n",
    "    Outputs:\n",
    "    -List_const: list with number of constraints violated. If no constraint is exceeded, then is empty\n",
    "    -Selectd_path: selected path for the routing. default value=none\n",
    "    -VariableValues: Binary Tuple (openserver, newinstance, delay). Default values [0,0,0]\n",
    "    \"\"\"\n",
    "\n",
    "    List_const = []\n",
    "    Selected_path = None\n",
    "    VariableValues =  [0,0,0]\n",
    "    \n",
    "    # verifying the existence of a vnf instance of same type\n",
    "    Instances_c = solution_['NodeVNFInstances'].get(c, {}).get(vnf_type, None)\n",
    "    VNFCapFailure = False \n",
    "    \n",
    "    if Instances_c != None:  #There is at least a VNf instance of the same type\n",
    "        # Verify instances capacity\n",
    "        VNFCapFailure = True\n",
    "        for inst in Instances_c:\n",
    "            if solution_['VNFCapacity'][vnf_type][inst] >= row['Demand']:\n",
    "                VNFCapFailure = False\n",
    "                break\n",
    "                \n",
    "    if Instances_c==None or VNFCapFailure: #There is not instances or they do not have capacity\n",
    "        if solution_['ServersCap'][c]< capacity_ct[vnf_type]:   #the candidate does not have more capacity\n",
    "            List_const.append('C1')\n",
    "            if VNFCapFailure:\n",
    "                List_const.append('C2')\n",
    "        else:\n",
    "            # I should create a new instance of vnf_type, but before we need to verify the max num instances\n",
    "            if len(solution_['VNFInstances'].get(vnf_type, []))+1>M_t[vnf_type]:\n",
    "                List_const.append('C4')\n",
    "    \n",
    "    # verifying UPF constraints\n",
    "    if vnf_type==1:  # It's a PSA UPF\n",
    "        for v in solution_['SFCMapping'].get(row['SessionId'], {}).get('VNFs', {}).values():\n",
    "            # Anti-affinity constraint:\n",
    "            if v[0]==vnf_type and v[2]==c:   # v--> (type, instance, c)\n",
    "                List_const.append('C16')\n",
    "                break\n",
    "            # PSA_IUPF constraint:\n",
    "            elif v[0]==2 and v[2]==c:   # v--> (type, instance, c)\n",
    "                List_const.append('C17')\n",
    "                break\n",
    "                \n",
    "    # finding the shortest path with available capacity\n",
    "    pathid=[]\n",
    "    pathdelay=[]\n",
    "    for k,v in Paths.items():\n",
    "        if k[0]==source_vnf and k[1]==c:\n",
    "            pathid.append(k)\n",
    "            pathdelay.append(v)\n",
    "    SortedPaths = [x for _,x in sorted(zip(pathdelay, pathid))]     # sorting the paths by their prop delay        \n",
    "    \n",
    "    #checking path capacity\n",
    "    for path in SortedPaths:\n",
    "        LinkCapFailure = False\n",
    "        for link,v in Paths_links_mapping[path].items():\n",
    "            if v==1: #verify link capacity\n",
    "                if solution_['LinksCap'][link]<row['Bw']:\n",
    "                    LinkCapFailure = True\n",
    "                    break\n",
    "        if not LinkCapFailure:\n",
    "            Selected_path = path\n",
    "            break\n",
    "            \n",
    "    if Selected_path==None: \n",
    "        List_const.append('C3')\n",
    "    \n",
    "    if len(List_const)==0:\n",
    "        # Determing the VariableValues\n",
    "        if solution_['NodeVNFInstances'].get(c, None)== None:\n",
    "            VariableValues[0] = 1\n",
    "            VariableValues[1] = 1\n",
    "        elif VNFCapFailure or Instances_c == None:\n",
    "            VariableValues[1] = 1\n",
    "        VariableValues[2] = Paths[Selected_path]/100\n",
    "        \n",
    "    return List_const, Selected_path, VariableValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulating_vnfdeployment(solution_2, c, vnf_id, vnf_type, Selected_path, VariableValues, row):\n",
    "    \"\"\"\n",
    "    This function will simulate the deployment of vnf in c to analize the deployment posibilities for the next \n",
    "    vnf if the current location is selected.\n",
    "    1-To simulate the deployment we will create a copy of the sets and add the mapping of vnf to links and nodes\n",
    "    2-Find next VNF in the branch \n",
    "    3-Take c as source for vnf+1 and determine the candidates\n",
    "    3-Evaluate each candidate\n",
    "    4-Select the best candidate\n",
    "    \"\"\"  \n",
    "    \n",
    "    #Updating the Sets\n",
    "    if VariableValues[0]==1:                    \n",
    "        # Opening of a new server   \n",
    "        solution_2['OpenServers'].append(c)\n",
    "        \n",
    "    if VariableValues[1]==1:\n",
    "        # create a new instance of vnf_type   \n",
    "        solution_2['ServersCap'][c] -= capacity_ct[vnf_type]\n",
    "        instance = len(solution_2['VNFInstances'].get(vnf_type, []))+1\n",
    "        solution_2['VNFInstances'].setdefault(vnf_type,[]).append(instance)\n",
    "        solution_2['VNFCapacity'].setdefault(vnf_type,{})[instance] = capacity_ct[vnf_type]\n",
    "        solution_2['NodeVNFInstances'].setdefault(c, {}).setdefault(vnf_type,[]).append(instance)\n",
    "    \n",
    "    else:  \n",
    "        # find instance with capacity\n",
    "        for instance in solution_2['NodeVNFInstances'][c][vnf_type]:\n",
    "            if solution_2['VNFCapacity'][vnf_type][instance] >= row['Demand']:\n",
    "                break\n",
    "\n",
    "    # update capacity\n",
    "    solution_2['VNFCapacity'][vnf_type][instance] = round(solution_2['VNFCapacity'][vnf_type][instance]-row['Demand'],2)\n",
    "    solution_2['SFCMapping'].setdefault(row['SessionId'], {}).setdefault('VNFs', {})[vnf_id] = (vnf_type, instance, c)\n",
    "    solution_2['SFCMapping'].setdefault(row['SessionId'], {}).setdefault('Paths', []).append(Selected_path)\n",
    "    solution_2['VNFSFCAssigned'].setdefault(vnf_type,{}).setdefault(instance,[]).append(row['SessionId'])\n",
    "\n",
    "    for link,v in Paths_links_mapping[Selected_path].items():\n",
    "        if v==1: \n",
    "            #update link capacity\n",
    "            solution_2['LinksCap'][link]-= row['Bw']\n",
    "    \n",
    "    return solution_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidates(solution_, candidates_set, source, v_type, row, candidates_sfcr, sfcr_u ):\n",
    "    \"\"\"\n",
    "    Determines which candidates in the set are feasible and which one not for the deployment of the selected vnf\n",
    "    sfcr_u: Number of SFCR remaining for assignment\n",
    "    \"\"\"\n",
    "\n",
    "    unfeasible_candidates = {} \n",
    "    feasible_cadidates = {}  \n",
    "\n",
    "    #Verify candidate\n",
    "    for c in candidates_set:\n",
    "        list_const, selected_path, variablevalues = verify_candidate(solution_, c, source, v_type, row)  \n",
    "        \n",
    "        if len(list_const) == 0 and selected_path != None:   \n",
    "            #Feasible candidate\n",
    "            # cost function including node popularity\n",
    "            cost_c = sum([(a*b)/c for a,b,c in zip(WeightFactors, variablevalues, NormalizationValues)]) + variablevalues[1]*(1-(len(candidates_sfcr[c])/sfcr_u)) \n",
    "            #original\n",
    "            # cost_c = sum([(a*b)/c for a,b,c in zip(WeightFactors, variablevalues, NormalizationValues)])    \n",
    "            \n",
    "            feasible_cadidates[c] = [selected_path, variablevalues, cost_c]\n",
    "        else:                                           \n",
    "            unfeasible_candidates[c] = list_const    # save Unfeasible candidate \n",
    "        \n",
    "    return feasible_cadidates, unfeasible_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_procedure(solution_copy, row, available_c, len_sessions, flag_look_ahead, available_nc):\n",
    "    \"\"\" \n",
    "    Thbis function is in charge of mapping the vnfs in the sfcr, ite will return a flag indicating the \n",
    "    failure or success of the mapping procedure and a dict containing the data  associated  to the output status\"\"\"\n",
    "        \n",
    "    flag_mapping_error = False \n",
    "    flag_resources_released = False\n",
    "    VNFLoc = {}         #dict vnf_id as key and c, lprop as value\n",
    "    \n",
    "    for f_id, f_type  in zip(row['VNFs'], row['Type']):             # f , f_typev= vnf_id, vnf_type\n",
    "        if f_id not in VNFLoc.keys():  \n",
    "            # If the VNF has not been mapped yet, we need to analyze its placement solut.\n",
    "            best_cost = 1000\n",
    "            destination_vnf_f = []\n",
    "\n",
    "            # steps 5-8:\n",
    "            for branch, Lprop in zip(row['Presence'], row['L_prop']):\n",
    "                # Steps 9-11: Select the candidates that are common to all the source according to Lprop.\n",
    "                # In our specific case, the source is the same for all vnf. thus, we just need to update the candidates.\n",
    "                if f_id == 1:\n",
    "                    source_vnf_f = row['SourceBS']          # The BS is the initial source for all the branches\n",
    "                    Lprop_vnf_f = [Lprop]                   # This is also updated with the placement of each VNf in a branch\n",
    "                    candidates_f = row['Candidates']        # For the first vnf all candidates satisfy latency req\n",
    "                else:\n",
    "                    source_vnf_f = VNFLoc[1][0]    # esto es porq en el caso de anaísis es la misma source, first f\n",
    "                    Lprop_vnf_f = VNFLoc[1][1]      # esto es porq en el caso de anaísis es la misma source, first f\n",
    "                    # for previous_f_index in range(0,f_id-1):  # In case of having different sourcess\n",
    "                    #     if branch[previous_f_index] == 1:\n",
    "                    #         source = row['VNFs'][previous_f_index]\n",
    "                    # source_vnf_f,append(VNFLoc[source][0])                                       \n",
    "                    # Lprop_vnf_f.append(VNFLoc[source][1])\n",
    "                    candidates_f = determine_candidates(source_vnf_f, Lprop_vnf_f, available_c)\n",
    "\n",
    "                # determining if f is the last vnf in the chain: In our specific case, it is easier to see the type of the vnf.\n",
    "                #  I it's the last, we do not need to determine the destination_vnfs\n",
    "                if f_type != 1 and flag_look_ahead:               \n",
    "                    for next_f_index in range(f_id,len(row['VNFs'])):  # f_idstarts in 1, thus if we used to iterate,       \n",
    "                                                                    # we will be looking at the next vnfs.\n",
    "                        if branch[next_f_index] == 1:     \n",
    "                            destination_vnf_f.append(row['VNFs'][next_f_index])\n",
    "                            break  \n",
    "                            \n",
    "            # steps 12-14: Evaluate candidates\n",
    "            feasible_cadidates, unfeasible_candidates = evaluate_candidates(solution_copy,candidates_f,source_vnf_f,\n",
    "                                                                            f_type, row, Candidates_sfcr,\n",
    "                                                                            len_sessions) \n",
    "            # steps 17: sort feasible candidates by their cost in ascending order\n",
    "            sorted_candidates_f = sorted(feasible_cadidates.keys(), key=lambda k: feasible_cadidates[k][2])\n",
    "            \n",
    "            for c in sorted_candidates_f:\n",
    "                selected_path, variablevalues, cost = feasible_cadidates[c]\n",
    "                if cost < best_cost:\n",
    "                    # step 20 & 27: simulating deployment of vnf f\n",
    "                    VNFLoc_aux = copy.deepcopy(VNFLoc)                                        \n",
    "                    solution_copy2 = copy.deepcopy(solution_copy)\n",
    "                    solution_copy2 = simulating_vnfdeployment(solution_copy2, c, f_id, f_type, selected_path, \n",
    "                                                              variablevalues, row)\n",
    "                #steps 15-: Looking-ahead\n",
    "                    if flag_look_ahead and f_type !=1:                    \n",
    "                        # Step 21: Sort next VNFs  by criticism (Not implemented)\n",
    "                        # Steps 22-: the following  first three lines should be for each next vnf but given that \n",
    "                        # they have similar features, I will do it just one time.\n",
    "                        Lprop_next_f = [Lprop_vnf_f[0]-Paths[selected_path]] \n",
    "                        candidates_next_f = determine_candidates(c, Lprop_next_f, available_c)\n",
    "                        VNFLoc_aux[f_id] = (c, Lprop_next_f) \n",
    "            \n",
    "                        for next_f_id in destination_vnf_f:\n",
    "                            # steps 24-25: Evaluate candidates\n",
    "                            feasible_cadidates_next_f, unfeasible_candidates = evaluate_candidates(solution_copy2,\n",
    "                                                                                            candidates_next_f, c, \n",
    "                                                                                            row['Type'][next_f_id-1],\n",
    "                                                                                            row, Candidates_sfcr, \n",
    "                                                                                            len_sessions)             \n",
    "                            if len(feasible_cadidates_next_f)!= 0:\n",
    "                                # steps 26: selecting the best candidates for the next vnf                            \n",
    "                                best_c_next_f = sorted(feasible_cadidates_next_f.keys(), key=lambda k: \n",
    "                                                             feasible_cadidates_next_f[k][2])[0]\n",
    "                                \n",
    "                                # Step 27: simulating deployment of next vnf\n",
    "                                solution_copy2 = simulating_vnfdeployment(solution_copy2, best_c_next_f, next_f_id, \n",
    "                                                                          row['Type'][next_f_id-1],\n",
    "                                                                          feasible_cadidates_next_f[best_c_next_f][0], \n",
    "                                                                          feasible_cadidates_next_f[best_c_next_f][1],\n",
    "                                                                          row)\n",
    "                                # Step 28: Update Cost\n",
    "                                cost += feasible_cadidates_next_f[best_c_next_f][2]\n",
    "                                VNFLoc_aux[next_f_id] = (best_c_next_f, Lprop_next_f[0]-\n",
    "                                                         Paths[feasible_cadidates_next_f[best_c_next_f][0]])                                \n",
    "                            else: \n",
    "                                cost += 1000    \n",
    "                                break\n",
    "\n",
    "                        if cost < best_cost:  # better candidate\n",
    "                            best_cost = cost\n",
    "                            best_solution = copy.deepcopy(solution_copy2)\n",
    "                            VNFLoc_best = copy.deepcopy(VNFLoc_aux)      \n",
    "\n",
    "                    else:\n",
    "                        best_cost = feasible_cadidates[c][2] \n",
    "                        best_solution = copy.deepcopy(solution_copy2)\n",
    "                        VNFLoc_best = copy.deepcopy(VNFLoc_aux) \n",
    "                        VNFLoc_best[f_id] = (c, [Lprop_vnf_f[0]-Paths[feasible_cadidates[c][0]]]) \n",
    "                        break     \n",
    "\n",
    "            # steps 33-34:        \n",
    "            if best_cost < 1000:\n",
    "                solution_copy = copy.deepcopy(best_solution)\n",
    "                VNFLoc = copy.deepcopy(VNFLoc_best)\n",
    "\n",
    "            else:\n",
    "                # PDT: Call reassign procedure()\n",
    "                if not flag_look_ahead:\n",
    "                    vnf_type = f_type   #pdt\n",
    "                \n",
    "                flag_mapping_error = True\n",
    "                print('unfeasible_candidates', row['SessionId'], unfeasible_candidates)\n",
    "                print('feasible_cadidates', row['SessionId'], feasible_cadidates)\n",
    "                flag_resources_released, solution_copy = reassign_procedure(source_vnf_f, Lprop_vnf_f, vnf_type, \n",
    "                                                                            flag_look_ahead, solution_copy, row,\n",
    "                                                                            available_nc, Candidates_sfcr,\n",
    "                                                                            len_sessions)\n",
    "                break\n",
    "                        \n",
    "    return flag_mapping_error, flag_resources_released, solution_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_procedure(source, lprop, cf_type, flag_look_ahead, solution_copy, row, available_nc, Candidates_sfcr,\n",
    "                      len_sessions):   \n",
    "    \"\"\"\n",
    "    This fucntion tries to map the SFCR that failed due to the absence of feasible candidates. This fucntionmay be uncompleted since\n",
    "    we do not used it during our experiments.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step1- Evaluate the candidates by including the ones that were discarded  due to capacity limitation\n",
    "    flag_resources_released = False\n",
    "    candidates_r = determine_candidates(source, lprop, available_nc)\n",
    "  \n",
    "    feasible_cadidates_r, unfeasible_candidates_r = evaluate_candidates(solution_copy, candidates_r, source, cf_type, \n",
    "                                                                    row, Candidates_sfcr, len_sessions)\n",
    "\n",
    "    # step2- select only the ones that are unfeasible due to capacity limitations only (C1 and7or C2). Selects\n",
    "    # the ones that have C2\n",
    "    selected_c = {}\n",
    "    for c,list_const in unfeasible_candidates_r.items():\n",
    "        print(c, list_const)\n",
    "        if list_const == ['C1', 'C2'] or list_const == ['C2']:\n",
    "            selected_c.append(c)\n",
    "\n",
    "    # step3: \n",
    "    if len(selected_c)!=0:\n",
    "        # step 4- define a set of untouchable candidates, the ones that are in the set of feasible candidates (para el approach\n",
    "        # of looking ahead. Para no look ahead, no importa porque el estado des estos ya puede incluir otras vnfs de la \n",
    "        # cadena, es decir, no se afectaría.)\n",
    "        untouchable_c = list(feasible_cadidates_r.keys())\n",
    "        touchable_c = [c for c in available_nc if c not in untouchable_c]\n",
    "        \n",
    "        # step5: Sort selected candidates by clossness to the source vnf.    \n",
    "        selected_c_distance_source = {}\n",
    "        for c in selected_c:\n",
    "            if (source,c,1) in Paths.keys():\n",
    "                selected_c_distance_source[c]=Paths[(source,c,1)] \n",
    "        sort_selected_c_distance_source = sorted(selected_c_distance_source.items(), key=lambda x: x[1])\n",
    "        \n",
    "        # step6- Release resources in this candidate \n",
    "        print('Uncomplete function')\n",
    "        raise\n",
    "\n",
    "    return flag_resources_released, solution_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initializing variables\n",
    "solution = {}\n",
    "solution['ServersCap'] = copy.deepcopy(capacity_nc)\n",
    "solution['LinksCap'] = copy.deepcopy(capacity_links)\n",
    "solution['OpenServers'] = []\n",
    "solution['VNFInstances'] = {}  # the key is the type of VNF and the value is a list of instances id\n",
    "solution['VNFCapacity'] = {}   # dict of dict, main dict key=type, valueis a dict key=instance_id & value=available cap\n",
    "solution['NodeVNFInstances'] = {} # dict of dict, main dict key=node id, valueis a dict key=vnf_type & value=instance id\n",
    "solution['VNFSFCAssigned'] = {} # dict of dict, main dict key=type, valueis a dict key=instance_id & value=sfc id\n",
    "solution['SFCMapping'] = {} # dict of dict, main dict key=pdu id, value= dict key=vnf_id(f)& value=type,instance_id,nodeId\n",
    "SFCUnmapped = []\n",
    "Count_reassig = 0\n",
    "\n",
    "SessionInfo = critic_classifier(SessionInfo, Available_nc)\n",
    "SortedSessionInfo = copy.deepcopy(SessionInfo)\n",
    "Available_c = copy.deepcopy(Available_nc)\n",
    "\n",
    "#Sorting SFCR \n",
    "SortedSessionInfo = SortedSessionInfo.sort_values(by=['Critic', 'Latency', 'NumVNFs', 'NumCand', 'SourceBS'],\n",
    "                                            ascending=[False, True, False, True, True])\n",
    "                                            \n",
    "flag_look_ahead = True\n",
    "# flag_look_ahead = import_data(dir_data, \"flag_look_ahead\") \n",
    "flag_reasing = False   #no implementado\n",
    "\n",
    "start_time = time.process_time()\n",
    "\n",
    "#Determining foreach candidates the sfcr that it can serve\n",
    "Candidates_sfcr = {}\n",
    "for c in Available_c:\n",
    "    Candidates_sfcr[c] = []\n",
    "for index, row in SessionInfo.iterrows():\n",
    "    for c in row['Candidates']:\n",
    "        Candidates_sfcr[c].append(row['SessionId'])\n",
    "\n",
    "while len(SortedSessionInfo) != 0:\n",
    "    solution_copy = copy.deepcopy(solution)\n",
    "    row = SortedSessionInfo.iloc[0]   #selecting the first SFCR in the sorted  set\n",
    "    len_sessions = len(SortedSessionInfo)\n",
    "    \n",
    "    # Procedure: mapping\n",
    "    flag_mapping_error, flag_resources_released, solution_copy = mapping_procedure(solution_copy, row, Available_c, \n",
    "                                                                                   len_sessions, flag_look_ahead, \n",
    "                                                                                   Available_nc)\n",
    "    # Procedure: reassign\n",
    "    if flag_mapping_error and flag_resources_released:\n",
    "        raise\n",
    "        flag_reasing = False\n",
    "        Count_reassig += 1\n",
    "    \n",
    "    # steps 40- : Update resources and (un)mapping set            \n",
    "    if not flag_mapping_error or flag_reasing:  \n",
    "        solution = copy.deepcopy(solution_copy)\n",
    "        #checking if we need o delete some candidate\n",
    "        flag_sort_sfcr = False\n",
    "\n",
    "        for c, instances in solution['NodeVNFInstances'].items():\n",
    "            if solution['ServersCap'][c] == 0 and c in Available_c:   # Analize available capacity of VNFs in c\n",
    "                flag_update_c = True\n",
    "                for typ,id_f in instances.items():\n",
    "                    for f in id_f:\n",
    "                        if solution['VNFCapacity'][typ][f] > 0:\n",
    "                            flag_update_c = False\n",
    "                            break\n",
    "                    if not flag_update_c: break\n",
    "                if flag_update_c:\n",
    "                    flag_sort_sfcr = True\n",
    "                    Available_c = [i for i in Available_c if i!=c]\n",
    "\n",
    "        if flag_sort_sfcr:\n",
    "            SortedSessionInfo = critic_classifier(SortedSessionInfo, Available_c)\n",
    "            #Sorting SFCR \n",
    "            SortedSessionInfo = SortedSessionInfo.sort_values(by=['Critic', 'Latency', 'NumVNFs', 'NumCand', 'SourceBS'],\n",
    "                                                                ascending=[False, True, False, True, True])        \n",
    "    else:\n",
    "        SFCUnmapped.append(row['SessionId'])              \n",
    "        \n",
    "    # updating the set of SFCR and Candidates_sfcr\n",
    "    SortedSessionInfo = SortedSessionInfo.drop(SortedSessionInfo.index[0]) \n",
    "    for k,v in Candidates_sfcr.items(): \n",
    "        if row['SessionId'] in v: Candidates_sfcr[k].remove(row['SessionId'])\n",
    "    \n",
    "T_exec = time.process_time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(solution,WeightFactors, NormalizationValues):\n",
    "    \"\"\"Calculates cost of the solution according to their weight in the objective function.\"\"\"\n",
    "    \n",
    "    num_open_servers = len(solution['OpenServers'])\n",
    "    num_upf_instances = sum([len(v) for v in solution['VNFInstances'].values()])\n",
    "    \n",
    "    latency_prop = 0\n",
    "    branches = 0\n",
    "    for k,v in solution['SFCMapping'].items():\n",
    "        for branch in SessionInfo[SessionInfo['SessionId']==k]['Presence'].values[0]:\n",
    "            latency_branch = sum([Paths[a]*b for a,b in zip(v['Paths'],branch)])    # one way \n",
    "            latency_prop += latency_branch\n",
    "            branches += 1\n",
    "\n",
    "    variable_values = [num_open_servers, num_upf_instances, latency_prop/branches]\n",
    "    cost = sum([a*b/c for a,b,c in zip(WeightFactors,variable_values,NormalizationValues)])\n",
    "    # print(' Cost_evaluation :' , cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_upf = 0\n",
    "Num_upf_type = {}\n",
    "\n",
    "for k,v in solution['VNFInstances'].items():\n",
    "    Total_upf += len(v)\n",
    "    Num_upf_type[k] = len(v)\n",
    "    \n",
    "# Number of open servers\n",
    "Num_open_c = len(solution['OpenServers'])\n",
    "Open_servers_list = solution['OpenServers']\n",
    "\n",
    "#Number of Unassigned sessions \n",
    "Num_unassigned_s = len(SFCUnmapped)\n",
    "Unassigned_s_list = SFCUnmapped\n",
    "\n",
    "\n",
    "# Laltency\n",
    "Latency_List = []\n",
    "\n",
    "for index, row in SessionInfo.iterrows():\n",
    "    if row['SessionId'] in solution['SFCMapping'].keys():\n",
    "        if row['Branches']==2:\n",
    "            Lprop_m =[Paths[solution['SFCMapping'][row['SessionId']]['Paths'][0]]+Paths[solution['SFCMapping'][row['SessionId']]['Paths'][1]]\n",
    "                      ,Paths[solution['SFCMapping'][row['SessionId']]['Paths'][0]]+Paths[solution['SFCMapping'][row['SessionId']]['Paths'][2]]]\n",
    "            for branch, Lprop_b, Lprop in zip(row['Presence'], row['L_prop'], Lprop_m ):\n",
    "        #         print(Lprop, branch)\n",
    "                Lproc = row['Latency']-2*Lprop_b\n",
    "                Latency_List.append(Lproc+2*Lprop)\n",
    "        else:\n",
    "            Lproc = row['Latency']-2*row['L_prop'][0] \n",
    "            Lprop = 0\n",
    "            for path in solution['SFCMapping'][row['SessionId']]['Paths']:\n",
    "                Lprop += Paths[path]\n",
    "\n",
    "            Latency_List.append(Lproc+2*Lprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cost_evaluation : 0.34595445997975854\n"
     ]
    }
   ],
   "source": [
    "cost = get_cost(solution,WeightFactors, NormalizationValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Execution time 1.34375\n",
      "   Placement Cost 0.3219933528816182\n",
      "   Number of UPF installed:  18\n",
      "   Number of UPFs per type {3: 4, 1: 11, 2: 3}\n",
      "   Open servers list [5, 4, 1, 8, 3, 9]\n",
      "   Number of Open Servers 6\n",
      "   Num_unassigned sessions 0\n",
      "   Number of Reassignations 0\n"
     ]
    }
   ],
   "source": [
    "print('   Execution time', T_exec)\n",
    "print('   Placement Cost', cost)\n",
    "print('   Number of UPF installed: ', Total_upf )\n",
    "print('   Number of UPFs per type', Num_upf_type )\n",
    "print('   Open servers list', Open_servers_list )\n",
    "print('   Number of Open Servers', Num_open_c )\n",
    "print('   Num_unassigned sessions', Num_unassigned_s)\n",
    "print('   Number of Reassignations', Count_reassig )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1124073dee199d8e1894afd18905e6ab65c2b78c2f71f2204c8c819619ccb15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
